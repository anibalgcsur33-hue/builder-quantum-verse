# ğŸ¤– Avatar 3D Setup Instructions

## ğŸ“‹ Requisitos Completados

âœ… **Componente Avatar3D** - Integrado con three.js y lip sync  
âœ… **Endpoints Backend** - `/api/speak` y `/api/visemes`  
âœ… **Sistema de AnimaciÃ³n** - Bucle de renderizado y control de estado  
âœ… **Interfaz de Usuario** - Controles de voz y acciones inmobiliarias  

## ğŸ¯ Pasos Pendientes

### 1. Avatar GLB Model Setup

**UbicaciÃ³n requerida:** `public/assets/avatar.glb`

**Requisitos del modelo:**
- âœ… Esqueleto Humanoid (Hips/Spine/Head/Arms)
- âœ… Blendshapes faciales con nombres estÃ¡ndar:
  - `viseme_aa` (AA/aah)
  - `viseme_oh` (O/oh) 
  - `viseme_ee` (E/ee)
  - `viseme_uw` (U/oo)
  - `viseme_mbp` (M/mbp)
  - `viseme_l` (L)
  - `viseme_w` (WQ)
  - `viseme_ch` (CH/tCH)
  - `viseme_fv` (FV)

**Herramientas recomendadas:**
- [Ready Player Me](https://readyplayer.me) - Avatares con blendshapes automÃ¡ticos
- [Blender](https://blender.org) - Para crear/editar blendshapes manualmente
- [Mixamo](https://mixamo.com) - Para animaciones idle (respirar, mirar)

### 2. TTS Integration (Backend)

**Archivo:** `netlify/functions/speak.ts`

**Servicios TTS recomendados:**
- **Coqui TTS** (local): `pip install coqui-tts`
- **Piper TTS** (local): MÃ¡s ligero, buena calidad
- **OpenAI TTS** (API): `text-to-speech-1` model
- **Azure Speech** (API): Voces neurales en espaÃ±ol
- **Google Text-to-Speech** (API): WaveNet voices

**Ejemplo integraciÃ³n Coqui:**
```python
from TTS.api import TTS
tts = TTS("tts_models/es/css10/vits")
tts.tts_to_file(text="Hola, soy tu asistente", file_path="output.wav")
```

### 3. Lip Sync Integration (Backend)

**Archivo:** `netlify/functions/visemes.ts`

**Rhubarb Lip-Sync Setup:**
```bash
# Instalar Rhubarb
wget https://github.com/DanielSWolf/rhubarb-lip-sync/releases/download/v1.13.0/rhubarb-lip-sync-1.13.0-linux.zip
unzip rhubarb-lip-sync-1.13.0-linux.zip

# Uso bÃ¡sico
./rhubarb -f json input.wav > visemes.json
```

**Formato de salida esperado:**
```json
[
  {"time": 0.0, "phoneme": "X"},
  {"time": 0.12, "phoneme": "AA"},
  {"time": 0.25, "phoneme": "O"}
]
```

### 4. Usar el Avatar en BlueEyeHomes

**IntegraciÃ³n en componentes existentes:**

```tsx
import Avatar3D from '../components/Avatar3D';

// En la pÃ¡gina donde quieras el avatar
<Avatar3D 
  className="w-full max-w-2xl mx-auto"
  onInteraction={(action, data) => {
    switch(action) {
      case 'search-properties':
        // Redirigir a bÃºsqueda
        break;
      case 'schedule-visit':
        // Abrir calendario
        break;
      case 'legal-info':
        // Mostrar info legal
        break;
    }
  }}
/>
```

## ğŸš€ Testing & Development

### Testing Local

1. **Modelo placeholder:** Coloca cualquier GLB en `public/assets/avatar.glb`
2. **TTS mock:** Los endpoints devuelven datos simulados
3. **Test button:** Usa "Test Speech" para probar el sistema

### Testing ProducciÃ³n

1. **GLB real:** Modelo con blendshapes correctos
2. **TTS real:** Integrar Coqui/Piper/OpenAI
3. **Rhubarb:** Procesamiento real de lip sync

## ğŸ“± CaracterÃ­sticas Implementadas

### âœ… Sistema 3D Completo
- Carga de modelos GLB/GLTF
- IluminaciÃ³n profesional (Hemisphere + Directional)
- Sombras y efectos visuales
- DetecciÃ³n automÃ¡tica de SkinnedMesh

### âœ… Lip Sync Avanzado
- Mapeo automÃ¡tico de blendshapes
- AplicaciÃ³n de visemas con decay natural
- SincronizaciÃ³n precisa con audio
- Fallback para blendshapes faltantes

### âœ… Animaciones Vivas
- Mirada sutil (rotaciÃ³n de cabeza)
- Sistema de mixer para animaciones idle
- Estados emocionales (neutral, speaking, thinking)
- Transiciones suaves

### âœ… InteracciÃ³n Inmobiliaria
- BotÃ³n micrÃ³fono para speech-to-text
- Acciones especÃ­ficas del sector
- Estados visuales de escucha/habla
- Control de volumen

### âœ… UX Profesional
- Indicadores de estado en tiempo real
- Controles intuitivos
- Carga progresiva
- Responsive design

## ğŸ”§ ConfiguraciÃ³n Recomendada

### Desarrollo
- Usar GLB bÃ¡sico para testing
- Mock endpoints habilitados
- Debug logs activos

### ProducciÃ³n
- Avatar profesional de Ready Player Me
- TTS service (OpenAI/Azure para mejor calidad)
- Rhubarb local para lip sync
- Monitoreo de performance

## ğŸ“ PrÃ³ximos Pasos

1. **Subir avatar.glb** a `public/assets/`
2. **Configurar TTS service** en `speak.ts`
3. **Integrar Rhubarb** en `visemes.ts`
4. **Testing completo** con audio real
5. **Deployment** y optimizaciÃ³n

Â¡El sistema estÃ¡ listo para recibir el modelo 3D y los servicios de voz! ğŸ‰
